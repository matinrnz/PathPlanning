{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython.display import Image\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, environment_rows=11, environment_columns=11, ORDER_REWARD=100,\n",
    "                 TERMINAL_PENALTY=-100, STEP_PENALTY=-1, START=(1,5), reward_locs=[(8,2),(2,7),(5,4),(8,7)]):\n",
    "        \n",
    "        self.environment_rows = environment_rows\n",
    "        self.environment_columns = environment_columns\n",
    "        self.ORDER_REWARD = ORDER_REWARD\n",
    "        self.TERMINAL_PENALTY = TERMINAL_PENALTY\n",
    "        self.STEP_PENALTY = STEP_PENALTY\n",
    "        self.START = START\n",
    "        self.reward_locs = reward_locs.copy() # rewards loc is a list, which is mutable, so we need to make a copy\n",
    "                                                # otherwise, the original list will be changed when we change the copy\n",
    "        self.reward_locs.append(START)\n",
    "        self.NUM_ORDERS = len(reward_locs)\n",
    "        self.orders_left = self.NUM_ORDERS        \n",
    "\n",
    "        # Call the build_environment function to initialize rewards\n",
    "        self.REWARDS_MAP = self.build_environment(reward_locs) # map of rewards that will not be updated, used for plotting\n",
    "        self.active_rewrads = self.REWARDS_MAP.copy() # copy of rewards map that will be updated as orders are completed\n",
    "        \n",
    "\n",
    "    def build_environment(self, reward_locs):\n",
    "        # Create a 2D numpy array to hold the rewards for each state.\n",
    "        rewards = np.full((self.environment_rows, self.environment_columns), self.TERMINAL_PENALTY)\n",
    "\n",
    "        # Define aisle locations (i.e., white squares) for rows 1 through 9\n",
    "        aisles = {}\n",
    "        aisles[0] = []\n",
    "        aisles[1] = [i for i in range(1, 10)]\n",
    "        aisles[2] = [1, 5, 9]\n",
    "        aisles[3] = [1, 5, 9]\n",
    "        aisles[4] = [i for i in range(1, 10)]\n",
    "        aisles[5] = [1, 5, 9]\n",
    "        aisles[6] = [i for i in range(1, 10)]\n",
    "        aisles[7] = [1, 5, 9]\n",
    "        aisles[8] = [1, 5, 9]\n",
    "        aisles[9] = [i for i in range(1, 10)]\n",
    "        aisles[10] = []\n",
    "\n",
    "        # Set the rewards for all aisle locations (i.e., white squares)\n",
    "        for row_index in range(0, 11):\n",
    "            for column_index in aisles[row_index]:\n",
    "                rewards[row_index, column_index] = self.STEP_PENALTY\n",
    "\n",
    "        # Set the reward for the packaging area (i.e., the goal) to ORDER_REWARD\n",
    "        for loc in reward_locs[:-1]:\n",
    "            rewards[loc[0], loc[1]] = self.ORDER_REWARD\n",
    "        \n",
    "        return rewards\n",
    "\n",
    "    def reset_active_rewards(self):\n",
    "        self.active_rewrads = self.REWARDS_MAP.copy()\n",
    "        self.orders_left = self.NUM_ORDERS    \n",
    "        \n",
    "    def is_terminal_state(self, current_row_index, current_column_index):\n",
    "        if self.active_rewrads[current_row_index, current_column_index] == self.TERMINAL_PENALTY:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def is_order_state(self, current_row_index, current_column_index, alter_rewards=True):\n",
    "        \"\"\"Returns True if the current state is an order state, False otherwise\n",
    "        \n",
    "        Also removes the order from the active rewards map, and updates the number of orders left\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if self.active_rewrads[current_row_index, current_column_index] == self.ORDER_REWARD:\n",
    "            if alter_rewards:\n",
    "                self.active_rewrads[current_row_index, current_column_index] = self.STEP_PENALTY\n",
    "                self.orders_left -= 1\n",
    "                #print(\"Order completed! Orders left: \", self.orders_left)\n",
    "                if self.orders_left == 1:\n",
    "                    self.active_rewrads[self.START[0], self.START[1]] = self.ORDER_REWARD\n",
    "                return True\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    \n",
    "    def get_starting_location(self):\n",
    "        return self.START[0], self.START[1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the shape of the environment (i.e., its states)\n",
    "environment_rows = 11\n",
    "environment_columns = 11\n",
    "ORDER_REWARD = 100\n",
    "TERMINAL_PENALTY = -100\n",
    "STEP_PENALTY = -1\n",
    "START = (1,5)\n",
    "reward_locs = [(8,2),(2,7),(5,4),(8,7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16910d9e5e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Environment class\n",
    "env = Environment(environment_rows, environment_columns, ORDER_REWARD, TERMINAL_PENALTY, STEP_PENALTY, START, reward_locs)\n",
    "\n",
    "# You can access the rewards array using env.rewards\n",
    "plt.imshow(env.REWARDS_MAP, cmap='hot', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 2), (2, 7), (5, 4), (8, 7), (1, 5)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_locs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.is_terminal_state(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Type\n",
    "from tqdm import tqdm\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self,environment_rows=11, environment_columns=11,ORDER_REWARD=100, TERMINAL_PENALTY=-100,\n",
    "                 STEP_PENALTY=-1, START=(1,5), reward_locs=[(8,2),(2,7),(5,4),(8,7)],actions=('up', 'right', 'down', 'left')):\n",
    "        \n",
    "        self.env = Environment(environment_rows, environment_columns,ORDER_REWARD, TERMINAL_PENALTY, STEP_PENALTY, START, reward_locs.copy())\n",
    "        self.q_values = np.zeros((self.env.NUM_ORDERS, environment_rows, environment_columns, 4))\n",
    "        self.environment_rows = environment_rows\n",
    "        self.environment_columns = environment_columns\n",
    "        self.actions = actions\n",
    "\n",
    "\n",
    "    def get_next_action(self, current_row_index, current_column_index, epsilon, order_number):\n",
    "        if np.random.random() < epsilon:\n",
    "            return np.argmax(self.q_values[order_number, current_row_index, current_column_index])\n",
    "        else:\n",
    "            return np.random.randint(4)\n",
    "\n",
    "    def get_next_location(self, current_row_index, current_column_index, action_index):\n",
    "        new_row_index = current_row_index\n",
    "        new_column_index = current_column_index\n",
    "        if self.actions[action_index] == 'up' and current_row_index > 0:\n",
    "            new_row_index -= 1\n",
    "        elif self.actions[action_index] == 'right' and current_column_index < self.environment_columns - 1:\n",
    "            new_column_index += 1\n",
    "        elif self.actions[action_index] == 'down' and current_row_index < self.environment_rows - 1:\n",
    "            new_row_index += 1\n",
    "        elif self.actions[action_index] == 'left' and current_column_index > 0:\n",
    "            new_column_index -= 1\n",
    "        else:\n",
    "            raise Exception(f\"Invalid action {action_index}\")\n",
    "        return new_row_index, new_column_index\n",
    "    \n",
    "    def get_shortest_path(self):\n",
    "        self.env.reset_active_rewards()\n",
    "        shortest_path = []\n",
    "        if self.env.is_terminal_state(self.env.START[0], self.env.START[1]) or self.env.is_order_state(self.env.START[0], self.env.START[1], alter_rewards=False):\n",
    "            print(f\"START: {self.env.START} | Terminal State: {self.env.is_terminal_state(self.env.START[0], self.env.START[1])} | Order State: {self.env.is_order_state(self.env.START[0], self.env.START[1], alter_rewards=False)}\")\n",
    "            print(f\"Rwards: {self.env.active_rewrads[self.env.START[0], self.env.START[1]]}\")\n",
    "            raise Exception(\"The starting location cannot be a terminal state or an order state!\")\n",
    "        current_row_index, current_column_index = self.env.get_starting_location()\n",
    "        shortest_path.append((current_row_index, current_column_index))\n",
    "        while not self.env.is_terminal_state(current_row_index, current_column_index) and self.env.orders_left > 0:\n",
    "            order_number = self.env.NUM_ORDERS - self.env.orders_left # order number is the number of orders completed so far which is the index of the current order and defines the q_values layer to use\n",
    "            action_index = self.get_next_action(current_row_index, current_column_index,1.0, order_number)\n",
    "            current_row_index, current_column_index = self.get_next_location(current_row_index, current_column_index, action_index)\n",
    "            shortest_path.append((current_row_index, current_column_index))\n",
    "            self.env.is_order_state(current_row_index, current_column_index)\n",
    "            \n",
    "            if len(shortest_path) > 1000:\n",
    "                print(\"Infinite loop! Something is wrong\")\n",
    "                break\n",
    "        return shortest_path\n",
    "    \n",
    "    def train(self, num_episodes, epsilon, discount_factor, learning_rate):\n",
    "        self.env.reset_active_rewards()\n",
    "        gamma = 1-(1 / (num_episodes/2))\n",
    "        progress_bar = tqdm(range(num_episodes), desc=\"Training Progress\", unit=\"Episode\")\n",
    "        zero_order_hit_count = 0\n",
    "        one_order_hit_count = 0\n",
    "        episode_rewards_list = []\n",
    "        for episode in progress_bar:\n",
    "            self.env.reset_active_rewards()\n",
    "            episode_rewards_sum = 0\n",
    "            row_index, column_index = self.env.get_starting_location()\n",
    "            \n",
    "            while not self.env.is_terminal_state(row_index, column_index) and self.env.orders_left > 0:\n",
    "                order_number = self.env.NUM_ORDERS - self.env.orders_left\n",
    "                action_index = self.get_next_action(row_index, column_index,epsilon, order_number=order_number)\n",
    "                \n",
    "                old_row_index, old_column_index = row_index, column_index # store the old row and column indexes\n",
    "                row_index, column_index = self.get_next_location(row_index, column_index, action_index)\n",
    "                \n",
    "                reward = self.env.active_rewrads[row_index, column_index]\n",
    "                episode_rewards_sum += reward\n",
    "                \n",
    "                old_q_value = self.q_values[order_number, old_row_index, old_column_index, action_index]\n",
    "                temporal_difference = reward + (discount_factor * np.max(self.q_values[order_number, row_index, column_index])) - old_q_value\n",
    "                new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
    "                self.q_values[order_number, old_row_index, old_column_index, action_index] = new_q_value\n",
    "                \n",
    "                if self.env.is_order_state(row_index, column_index):\n",
    "                    if self.env.orders_left == 0:\n",
    "                        zero_order_hit_count += 1\n",
    "                    elif self.env.orders_left == 1:\n",
    "                        one_order_hit_count += 1\n",
    "                \n",
    "            episode_rewards_list.append(episode_rewards_sum)\n",
    "            \n",
    "            learning_rate = max(learning_rate * gamma, 0.01)\n",
    "            epsilon = min(epsilon * (2-gamma), 0.9)\n",
    "\n",
    "            progress_bar.set_postfix({\"Ord left\": self.env.orders_left, \"lr\": learning_rate, \"Eps\": epsilon,\n",
    "                                      \"0 Order\":zero_order_hit_count, \"1 Order\":one_order_hit_count})\n",
    "        \n",
    "        progress_bar.close()\n",
    "        return episode_rewards_list\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 11, 11, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = QLearningAgent(environment_rows, environment_columns, ORDER_REWARD, TERMINAL_PENALTY, STEP_PENALTY, START, reward_locs)\n",
    "agent.q_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1000/1000 [00:00<00:00, 1327.01Episode/s, Ord left=1, lr=0.122, Eps=0.9, 0 Order=135, 1 Order=349]\n"
     ]
    }
   ],
   "source": [
    "reward_per_episode_list = agent.train(num_episodes=1000, epsilon=0.9, discount_factor=0.9, learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16911580280>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(agent.env.active_rewrads, cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.ORDER_REWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path = agent.get_shortest_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (2, 7),\n",
       " (1, 7),\n",
       " (1, 6),\n",
       " (1, 5),\n",
       " (2, 5),\n",
       " (3, 5),\n",
       " (4, 5),\n",
       " (5, 5),\n",
       " (5, 4),\n",
       " (6, 4),\n",
       " (6, 3),\n",
       " (6, 2),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (8, 2),\n",
       " (8, 1),\n",
       " (7, 1),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (5, 4),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (3, 5),\n",
       " (2, 5),\n",
       " (1, 5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
